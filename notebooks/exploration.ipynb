{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b178194f",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45b5e9e4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import GPT2LMHeadModel, GPT2Tokenizer, AutoTokenizer\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from dataclasses import dataclass\n",
    "from transformers import AutoConfig, AutoModelForCausalLM, PreTrainedModel\n",
    "from safetensors.torch import load_model, save_model, safe_open\n",
    "from weak_to_strong.model import TransformerWithHead\n",
    "import seaborn as sns\n",
    "from sklearn.decomposition import PCA\n",
    "from datasets import load_dataset\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from scipy.optimize import minimize\n",
    "from sklearn.utils import gen_batches\n",
    "from tqdm import tqdm\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b089418",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cpu'\n",
    "print(\"Using: \" + str(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6582c518-4ed4-4a48-a6ca-1d528b18157b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'NVIDIA H100 80GB HBM3'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.get_device_name()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1215bd5",
   "metadata": {},
   "source": [
    "# Representation Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7c0cba3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_activation(name, activations):\n",
    "    \"\"\" Helper function to capture the activation at each layer. \"\"\"\n",
    "    def hook(model, input, output):\n",
    "        # We expect 'output' to be a tuple where the first element is the last hidden state\n",
    "        activations[name] = output[0].detach().to(device)\n",
    "    return hook\n",
    "\n",
    "def extract_hidden_states(model, datapoint):\n",
    "    \"\"\" Extract hidden states for all layers of a given model for a specific datapoint. \"\"\"\n",
    "    activations = {}\n",
    "    hooks = []\n",
    "\n",
    "    # Registering hooks for each layer of the transformer\n",
    "    for name, module in model.transformer.named_modules():\n",
    "        if isinstance(module, torch.nn.modules.Module):  # You may want to filter only certain types of layers\n",
    "            hook = module.register_forward_hook(get_activation(name, activations))\n",
    "            hooks.append(hook)\n",
    "    \n",
    "    datapoint = datapoint.to(device)\n",
    "    \n",
    "    # Run the datapoint through the model\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        _ = model(datapoint)\n",
    "\n",
    "    # Remove hooks after use\n",
    "    for hook in hooks:\n",
    "        hook.remove()\n",
    "\n",
    "    return activations\n",
    "\n",
    "def compare_models(model_name, finetuned_model_path, datapoint): \n",
    "    \"\"\" Extract and compare hidden states from two models for a given datapoint. \"\"\"\n",
    "        # Load both models\n",
    "    pre_model = TransformerWithHead.from_pretrained(model_name).to(device)\n",
    "    post_model = TransformerWithHead.from_pretrained(model_name)\n",
    "    \n",
    "    load_model(post_model, finetuned_model_path,'cpu')\n",
    "    \n",
    "    post_model = post_model.to(device)\n",
    "    \n",
    "    # datapoint = datapoint.to(model1.device)  # Ensure datapoint is on the same device as model\n",
    "    activations_model1 = extract_hidden_states(pre_model, datapoint)\n",
    "    activations_model2 = extract_hidden_states(post_model, datapoint)\n",
    "    \n",
    "    return activations_model1, activations_model2\n",
    "\n",
    "def convert_input(text, model_name):\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_name) \n",
    "\n",
    "    # Tokenize the text and convert to input IDs\n",
    "    tokens = tokenizer.tokenize(text)\n",
    "    input_ids = tokenizer.convert_tokens_to_ids(tokens)\n",
    "\n",
    "    datapoint = torch.tensor([input_ids])\n",
    "    \n",
    "    return datapoint\n",
    "\n",
    "def print_layer_names(activations):\n",
    "    stor = []\n",
    "    for key, val in activations.items(): \n",
    "        stor.append(key)\n",
    "        print(key)\n",
    "    return key\n",
    "\n",
    "def extract_act_pipeline(model_name, train_data, finetuned_model_path, layer_name = \"h.11\"): \n",
    "    pre_ft_activations = []\n",
    "    post_ft_activations = []\n",
    "    print(\"Converting input to activations.\")\n",
    "    for datapoint in tqdm(train_data):\n",
    "        activations_model1, activations_model2 = compare_models(model_name, finetuned_model_path, datapoint)\n",
    "        pre_ft_activations.append(activations_model1[layer_name].squeeze(0))\n",
    "        post_ft_activations.append(activations_model2[layer_name].squeeze(0))\n",
    "    print(\"Activation Loaded.\")\n",
    "    return pre_ft_activations, post_ft_activations\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "257151bb-710c-4eb5-b75a-4a65129b8445",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_activation_changes(activations_pre, activations_post, layer_name, method='PCA', components=2):\n",
    "    \"\"\"\n",
    "    Visualize changes in activations using PCA or t-SNE.\n",
    "\n",
    "    Parameters:\n",
    "    activations_pre (dict): Activations from the model before finetuning.\n",
    "    activations_post (dict): Activations from the model after finetuning.\n",
    "    layer_name (str): The layer whose activations are to be visualized.\n",
    "    method (str): 'PCA' or 't-SNE', the method to use for dimensionality reduction.\n",
    "    components (int): Number of components for the dimensionality reduction.\n",
    "    \"\"\"\n",
    "    # Extract activations for a specific layer\n",
    "    data_pre = activations_pre[layer_name].cpu().numpy()\n",
    "    data_post = activations_post[layer_name].cpu().numpy()\n",
    "    \n",
    "    # Check if data is three-dimensional and apply mean pooling if so\n",
    "    if data_pre.ndim == 3:\n",
    "        # Mean across the sequence length dimension\n",
    "        data_pre = data_pre.mean(axis=0)\n",
    "    if data_post.ndim == 3:\n",
    "        # Mean across the sequence length dimension\n",
    "        data_post = data_post.mean(axis=0)\n",
    "    \n",
    "    # Concatenate data from both states for unified transformation in PCA/t-SNE\n",
    "    data_combined = np.concatenate([data_pre, data_post], axis=0)\n",
    "    \n",
    "    if method == 'PCA':\n",
    "        reducer = PCA(n_components=components)\n",
    "    elif method == 't-SNE':\n",
    "        reducer = TSNE(n_components=components, learning_rate='auto', init='random')\n",
    "    else:\n",
    "        raise ValueError(\"Unsupported dimensionality reduction method\")\n",
    "    \n",
    "    # Fit and transform the data\n",
    "    reduced_data = reducer.fit_transform(data_combined)\n",
    "    \n",
    "    # Split the transformed data\n",
    "    reduced_data_pre = reduced_data[:data_pre.shape[0]]\n",
    "    reduced_data_post = reduced_data[data_pre.shape[0]:]\n",
    "\n",
    "    # Plotting\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.scatter(reduced_data_pre[:, 0], reduced_data_pre[:, 1], c='blue', alpha=0.5, label='Pre-Finetuning')\n",
    "    plt.scatter(reduced_data_post[:, 0], reduced_data_post[:, 1], c='red', alpha=0.5, label='Post-Finetuning')\n",
    "    plt.title(f'Layer: {layer_name} - {method} Visualization')\n",
    "    plt.xlabel(f'{method} Component 1')\n",
    "    plt.ylabel(f'{method} Component 2')\n",
    "    plt.legend()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "85f9ea8d-075c-492c-a1eb-693bad8d4227",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### SCIPY MINIMIZE\n",
    "\n",
    "def loss_per_sample(params, lambda_x, lambda_x_tilde, dim):\n",
    "    A_len = dim**2\n",
    "    A = params[:A_len].reshape(dim, dim)\n",
    "    delta = params[A_len:].reshape(dim, 1)\n",
    "    transformed = lambda_x @ A + delta.T  # Note the transpose to match dimensions\n",
    "    loss = np.linalg.norm(transformed - lambda_x_tilde, 'fro')**2\n",
    "    return loss\n",
    "\n",
    "def loss_function(params, batch_pre_ft, batch_post_ft, dim):\n",
    "    losses = [loss_per_sample(params, pre_ft, post_ft, dim) for pre_ft, post_ft in zip(batch_pre_ft, batch_post_ft)]\n",
    "    return np.sum(losses) / len(batch_pre_ft)\n",
    "\n",
    "\n",
    "def optimize_Adelta(pre_ft_activations, post_ft_activations, batch_size, tol=1e-5, max_iter=10):\n",
    "    # activation list shape: n_sample * (token_num * feature)\n",
    "    # A shape: feature * feature\n",
    "    # delta shape: 1 * feature \n",
    "    # batch list shape: batch_size * (token_num * feature)\n",
    "    dim = pre_ft_activations[0].shape[1]\n",
    "    print(dim)\n",
    "    A_len = dim**2\n",
    "    print(A_len)\n",
    "\n",
    "    # Initialize A and delta\n",
    "    A_init = np.eye(dim).flatten()\n",
    "    delta_init = np.zeros((dim, 1)).flatten()\n",
    "    initial_params = np.concatenate([A_init, delta_init])\n",
    "\n",
    "    n_samples = len(pre_ft_activations)\n",
    "    previous_loss = np.inf\n",
    "    converged = False\n",
    "\n",
    "    # Function to perform optimization on a batch\n",
    "    def optimize_batch(start, end, params):\n",
    "        batch_pre_ft = pre_ft_activations[start:end]\n",
    "        batch_post_ft = post_ft_activations[start:end]\n",
    "\n",
    "        result = minimize(\n",
    "            fun=loss_function,\n",
    "            x0=params,\n",
    "            args=(batch_pre_ft, batch_post_ft, dim),\n",
    "            method= 'L-BFGS-B'\n",
    "        )\n",
    "        return result\n",
    "\n",
    "    # Iterate over mini-batches and optimize\n",
    "    for iteration in range(max_iter):\n",
    "        for batch in gen_batches(n_samples, batch_size):\n",
    "            result = optimize_batch(batch.start, batch.stop, initial_params)\n",
    "\n",
    "            if result.success:\n",
    "                initial_params = result.x\n",
    "                current_loss = result.fun\n",
    "                loss_change = previous_loss - current_loss\n",
    "                previous_loss = current_loss\n",
    "\n",
    "                print(f\"Iteration {iteration}, Batch {batch.start}-{batch.stop}, \"\n",
    "                      f\"Current Loss: {current_loss:.6f}, Loss Change: {loss_change:.6f}\")\n",
    "\n",
    "                if np.abs(loss_change) < tol:\n",
    "                    converged = True\n",
    "                    break\n",
    "            else:\n",
    "                print(f\"Optimization failed at Iteration {iteration}, Batch {batch.start}-{batch.stop}.\")\n",
    "                break\n",
    "\n",
    "        if converged:\n",
    "            print(\"Convergence criterion met.\")\n",
    "            break\n",
    "    else:\n",
    "        print(\"Reached maximum iterations without convergence.\")\n",
    "\n",
    "    # After going through all batches, reshape the final parameters back into A and delta\n",
    "    A_optimized = initial_params[:A_len].reshape(dim, dim)\n",
    "    delta_optimized = initial_params[A_len:].reshape(dim, 1)\n",
    "    \n",
    "    print(\"Optimization finished.\")\n",
    "    return A_optimized, delta_optimized\n",
    "\n",
    "def avg_samples(act_list): \n",
    "    # Compute the mean along the axis 0 (num_tokens dimension)\n",
    "    res = []\n",
    "    for act in act_list: \n",
    "        mean_values = torch.mean(act, dim=0)\n",
    "\n",
    "        result = mean_values.unsqueeze(0)\n",
    "        res.append(result)\n",
    "    return np.array(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7be66290",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Representation Predictions [fixed]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b645086a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def torch_loss_function(A, delta, lambda_x, lambda_x_tilde):\n",
    "    \"\"\"\n",
    "    Computes the loss for a batch of data.\n",
    "\n",
    "    Args:\n",
    "    A (torch.Tensor): The affine transformation matrix.\n",
    "    delta (torch.Tensor): The rank-one update vector.\n",
    "    lambda_x (torch.Tensor): Pre-finetuning activations (batch).\n",
    "    lambda_x_tilde (torch.Tensor): Post-finetuning activations (batch).\n",
    "\n",
    "    Returns:\n",
    "    torch.Tensor: The computed loss.\n",
    "    \"\"\"\n",
    "    # Compute the affine transformation and add delta\n",
    "    transformed = torch.mm(lambda_x, A) + delta\n",
    "    # Calculate the Frobenius norm of the difference, scaled by the number of samples\n",
    "    loss = torch.norm(transformed - lambda_x_tilde, p='fro') ** 2 / lambda_x.size(0)\n",
    "    return loss\n",
    "\n",
    "def optimize_Adelta(pre_ft_activations, post_ft_activations, batch_size, lr=1e-3, tol=1e-5, max_iter=20000):\n",
    "    \"\"\"\n",
    "    Optimizes A and delta parameters using the provided pre and post-finetuning activations.\n",
    "\n",
    "    Args:\n",
    "    pre_ft_activations (np.array): Pre-finetuning activations.\n",
    "    post_ft_activations (np.array): Post-finetuning activations.\n",
    "    dim (int): The dimensionality of each feature vector.\n",
    "    batch_size (int): The size of each batch for optimization.\n",
    "    lr (float): Learning rate for the optimizer.\n",
    "    tol (float): Tolerance for convergence.\n",
    "    max_iter (int): Maximum number of iterations.\n",
    "\n",
    "    Returns:\n",
    "    Tuple[np.array, np.array]: Optimized A and delta.\n",
    "    \"\"\"\n",
    "    dim = pre_ft_activations[0].shape[1]\n",
    "    # Convert numpy arrays to torch tensors\n",
    "    pre_ft_activations_tensor = torch.tensor(pre_ft_activations, dtype=torch.float32)\n",
    "    post_ft_activations_tensor = torch.tensor(post_ft_activations, dtype=torch.float32)\n",
    "    \n",
    "    # Initialize A and delta as torch tensors\n",
    "    A = nn.Parameter(torch.eye(dim, requires_grad=True))\n",
    "    delta = nn.Parameter(torch.zeros(1, dim, requires_grad=True))\n",
    "\n",
    "    # Use the Adam optimizer\n",
    "    optimizer = optim.Adam([A, delta], lr=lr)\n",
    "\n",
    "    previous_loss = float('inf')\n",
    "    for iteration in range(max_iter):\n",
    "        for i in range(0, len(pre_ft_activations), batch_size):\n",
    "            optimizer.zero_grad()\n",
    "            batch_pre_ft = pre_ft_activations_tensor[i:i+batch_size].squeeze(1)\n",
    "            batch_post_ft = post_ft_activations_tensor[i:i+batch_size].squeeze(1)\n",
    "#             print(batch_pre_ft.shape)\n",
    "#             print(batch_post_ft.shape)\n",
    "            loss = torch_loss_function(A, delta, batch_pre_ft, batch_post_ft)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            current_loss = loss.item()\n",
    "            if iteration % 50 == 0 and i == 0:  # Print the loss for the first batch every 10 iterations\n",
    "                print(f\"Iteration {iteration}, Loss: {current_loss:.6f}\")\n",
    "            \n",
    "            if abs(previous_loss - current_loss) < tol:\n",
    "                print(\"Convergence criterion met.\")\n",
    "                return A.detach().numpy(), delta.detach().numpy()\n",
    "            previous_loss = current_loss\n",
    "\n",
    "    print(\"Optimization finished.\")\n",
    "    return A.detach().numpy(), delta.detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cebefa9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "A, d = optimize_Adelta(final_preact, final_postact, batch_size = 256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e43a393e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def new_torch_loss_function(A, delta, lambda_x, lambda_x_tilde):\n",
    "    \"\"\"\n",
    "    Computes the loss for a batch of data.\n",
    "\n",
    "    Args:\n",
    "    A (torch.Tensor): The affine transformation matrix.\n",
    "    delta (torch.Tensor): The rank-one update vector.\n",
    "    lambda_x (torch.Tensor): Pre-finetuning activations (batch).\n",
    "    lambda_x_tilde (torch.Tensor): Post-finetuning activations (batch).\n",
    "\n",
    "    Returns:\n",
    "    torch.Tensor: The computed loss.\n",
    "    \"\"\"\n",
    "    # Compute the affine transformation and add delta\n",
    "    transformed = torch.mm(lambda_x, A) + lambda_x * delta\n",
    "    # Calculate the Frobenius norm of the difference, scaled by the number of samples\n",
    "    loss = torch.norm(transformed - lambda_x_tilde, p='fro') ** 2 / lambda_x.size(0)\n",
    "    return loss\n",
    "\n",
    "def optimize_Adelta_newloss(pre_ft_activations, post_ft_activations, batch_size, lr=1e-3, tol=1e-5, max_iter=20000):\n",
    "    \"\"\"\n",
    "    Optimizes A and delta parameters using the provided pre and post-finetuning activations.\n",
    "\n",
    "    Args:\n",
    "    pre_ft_activations (np.array): Pre-finetuning activations.\n",
    "    post_ft_activations (np.array): Post-finetuning activations.\n",
    "    dim (int): The dimensionality of each feature vector.\n",
    "    batch_size (int): The size of each batch for optimization.\n",
    "    lr (float): Learning rate for the optimizer.\n",
    "    tol (float): Tolerance for convergence.\n",
    "    max_iter (int): Maximum number of iterations.\n",
    "\n",
    "    Returns:\n",
    "    Tuple[np.array, np.array]: Optimized A and delta.\n",
    "    \"\"\"\n",
    "    dim = pre_ft_activations[0].shape[1]\n",
    "    # Convert numpy arrays to torch tensors\n",
    "    pre_ft_activations_tensor = torch.tensor(pre_ft_activations, dtype=torch.float32)\n",
    "    post_ft_activations_tensor = torch.tensor(post_ft_activations, dtype=torch.float32)\n",
    "    \n",
    "    # Initialize A and delta as torch tensors\n",
    "    A = nn.Parameter(torch.eye(dim, requires_grad=True))\n",
    "    delta = nn.Parameter(torch.zeros(1, dim, requires_grad=True))\n",
    "\n",
    "    # Use the Adam optimizer\n",
    "    optimizer = optim.Adam([A, delta], lr=lr)\n",
    "\n",
    "    previous_loss = float('inf')\n",
    "    for iteration in range(max_iter):\n",
    "        for i in range(0, len(pre_ft_activations), batch_size):\n",
    "            optimizer.zero_grad()\n",
    "            batch_pre_ft = pre_ft_activations_tensor[i:i+batch_size].squeeze(1)\n",
    "            batch_post_ft = post_ft_activations_tensor[i:i+batch_size].squeeze(1)\n",
    "#             print(batch_pre_ft.shape)\n",
    "#             print(batch_post_ft.shape)\n",
    "            loss = new_torch_loss_function(A, delta, batch_pre_ft, batch_post_ft)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            current_loss = loss.item()\n",
    "            if iteration % 50 == 0 and i == 0:  # Print the loss for the first batch every 10 iterations\n",
    "                print(f\"Iteration {iteration}, Loss: {current_loss:.6f}\")\n",
    "            \n",
    "            if abs(previous_loss - current_loss) < tol:\n",
    "                print(\"Convergence criterion met.\")\n",
    "                return A.detach().numpy(), delta.detach().numpy()\n",
    "            previous_loss = current_loss\n",
    "\n",
    "    print(\"Optimization finished.\")\n",
    "    return A.detach().numpy(), delta.detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd50b2bd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "newA, newd = optimize_Adelta_newloss(final_preact, final_postact, batch_size = 256)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69235af5",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# LORA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43d68850",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "def torch_loss_function_lora(B, C, delta, lambda_x, lambda_x_tilde):\n",
    "    \"\"\"\n",
    "    Computes the loss for a batch of data using LORA.\n",
    "\n",
    "    Args:\n",
    "    B, C (torch.Tensor): Low-rank matrices decomposing A.\n",
    "    delta (torch.Tensor): The rank-one update vector.\n",
    "    lambda_x (torch.Tensor): Pre-finetuning activations (batch).\n",
    "    lambda_x_tilde (torch.Tensor): Post-finetuning activations (batch).\n",
    "\n",
    "    Returns:\n",
    "    torch.Tensor: The computed loss.\n",
    "    \"\"\"\n",
    "    A = torch.mm(B, C)  # Reconstruct A from B and C\n",
    "    transformed = torch.mm(lambda_x, A) + delta\n",
    "    loss = torch.norm(transformed - lambda_x_tilde, p='fro') ** 2 / lambda_x.size(0)\n",
    "    return loss\n",
    "\n",
    "def optimize_lora(pre_ft_activations, post_ft_activations, rank= 3, batch_size=256, lr=1e-3, tol=1e-5, max_iter=10000):\n",
    "    \"\"\"\n",
    "    Optimizes B, C, and delta parameters using LORA.\n",
    "\n",
    "    Args:\n",
    "    pre_ft_activations, post_ft_activations (np.array): Activation arrays.\n",
    "    rank (int): Rank for the low-rank decomposition of A.\n",
    "    batch_size (int): Batch size for optimization.\n",
    "    lr (float): Learning rate.\n",
    "    tol (float): Tolerance for convergence.\n",
    "    max_iter (int): Max number of iterations.\n",
    "\n",
    "    Returns:\n",
    "    Tuple[np.array, np.array, np.array]: Optimized B, C, and delta.\n",
    "    \"\"\"\n",
    "    dim = pre_ft_activations[0].shape[1]\n",
    "    pre_ft_activations_tensor = torch.tensor(pre_ft_activations, dtype=torch.float32)\n",
    "    post_ft_activations_tensor = torch.tensor(post_ft_activations, dtype=torch.float32)\n",
    "    \n",
    "    B = nn.Parameter(torch.randn(dim, rank, requires_grad=True))\n",
    "    C = nn.Parameter(torch.randn(rank, dim, requires_grad=True))\n",
    "    delta = nn.Parameter(torch.zeros(1, dim, requires_grad=True))\n",
    "\n",
    "    optimizer = optim.Adam([B, C, delta], lr=lr)\n",
    "\n",
    "    previous_loss = float('inf')\n",
    "    for iteration in range(max_iter):\n",
    "        for i in range(0, len(pre_ft_activations), batch_size):\n",
    "            optimizer.zero_grad()\n",
    "            batch_pre_ft = pre_ft_activations_tensor[i:i+batch_size].squeeze(1)\n",
    "            batch_post_ft = post_ft_activations_tensor[i:i+batch_size].squeeze(1)\n",
    "            loss = torch_loss_function_lora(B, C, delta, batch_pre_ft, batch_post_ft)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            current_loss = loss.item()\n",
    "            if iteration % 50 == 0 and i == 0:\n",
    "                print(f\"Iteration {iteration}, Loss: {current_loss:.6f}\")\n",
    "            \n",
    "            if abs(previous_loss - current_loss) < tol:\n",
    "                print(\"Convergence criterion met.\")\n",
    "                return B.detach().numpy(), C.detach().numpy(), delta.detach().numpy()\n",
    "            previous_loss = current_loss\n",
    "\n",
    "    print(\"Optimization finished.\")\n",
    "    return B.detach().numpy(), C.detach().numpy(), delta.detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95a73000",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "B, C, delta = optimize_lora(final_preact, final_postact, max_iter=10000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33ea7fd2",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Ground Truth Linear Probe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b306c96",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "def linear_probe(activations, labels):\n",
    "\n",
    "    X = np.array([(np.array([1]) + act.detach().cpu().numpy()).mean(axis=0) for act in activations])\n",
    "    y = np.array(labels)\n",
    "\n",
    "    print(X.shape)\n",
    "    # Split into train and test sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "    # Initialize and train the linear classifier\n",
    "    clf = LogisticRegression(max_iter=1000)\n",
    "    clf.fit(X_train, y_train)\n",
    "\n",
    "    # Predict on the test set\n",
    "    y_pred = clf.predict(X_test)\n",
    "\n",
    "    # Calculate the accuracy\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    print(f'Accuracy: {accuracy:.2f}')\n",
    "    return clf\n",
    "\n",
    "def cosine_similarity_torch(vec1, vec2):\n",
    "    vec1 = torch.tensor(vec1)\n",
    "    vec2 = torch.tensor(vec2)\n",
    "    \n",
    "    similarity = F.cosine_similarity(vec1, vec2)\n",
    "    \n",
    "    return similarity\n",
    "\n",
    "def plot_vecs(weights, d):\n",
    "    try: \n",
    "        weights_np = weights.detach().numpy() if weights.requires_grad else weights.numpy()\n",
    "        d_np = d.detach().numpy() if d.requires_grad else d.numpy()\n",
    "    except Exception: \n",
    "        weights_np = weights\n",
    "        d_np = d\n",
    "    # Stack the vectors for PCA\n",
    "    data = np.vstack([weights_np, d_np])\n",
    "\n",
    "    # Initialize PCA to reduce to 2 dimensions\n",
    "    pca = PCA(n_components=2)\n",
    "    data_reduced = pca.fit_transform(data)\n",
    "\n",
    "    # Plot the reduced data\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.scatter(data_reduced[:, 0], data_reduced[:, 1], c=['red', 'blue'], label=['Weights', 'd'])\n",
    "    plt.xlabel('Principal Component 1')\n",
    "    plt.ylabel('Principal Component 2')\n",
    "    plt.title('2D Visualization of High-Dimensional Vectors')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "923c17db",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = []\n",
    "for i in tqdm(range(len(post_ft_activations))): \n",
    "    labels.append(ds[\"train\"][i][\"label\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9620ba3",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = linear_probe(post_ft_activations, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c5793ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = clf.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57e6e55e",
   "metadata": {},
   "outputs": [],
   "source": [
    "weights.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bfbf805",
   "metadata": {},
   "outputs": [],
   "source": [
    "d.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56b2de6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "similarity = cosine_similarity_torch(weights, d)\n",
    "print(\"Cosine similarity:\", similarity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9961c64",
   "metadata": {},
   "outputs": [],
   "source": [
    "similarity = cosine_similarity_torch(weights, delta)\n",
    "print(\"Cosine similarity:\", similarity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69c7abcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "similarity = cosine_similarity_torch(d, delta)\n",
    "print(\"Cosine similarity:\", similarity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4051970e",
   "metadata": {},
   "outputs": [],
   "source": [
    "similarity = cosine_similarity_torch(weights, newd)\n",
    "print(\"Cosine similarity:\", similarity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "825bba91",
   "metadata": {},
   "outputs": [],
   "source": [
    "similarity = cosine_similarity_torch(delta, newd)\n",
    "print(\"Cosine similarity:\", similarity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f61bb891",
   "metadata": {},
   "outputs": [],
   "source": [
    "similarity = cosine_similarity_torch(d, newd)\n",
    "print(\"Cosine similarity:\", similarity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d492eeb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "similarity = cosine_similarity_torch(newd, weights)\n",
    "print(\"Cosine similarity:\", similarity)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29ae67e5",
   "metadata": {},
   "source": [
    "# data prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77c37796",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = load_dataset(\"amazon_polarity\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "be1251b2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed 0\n",
      "Completed 1\n",
      "Completed 2\n",
      "Completed 3\n",
      "Completed 4\n",
      "Completed 5\n",
      "Completed 6\n",
      "Completed 7\n",
      "Completed 8\n",
      "Completed 9\n",
      "Completed 10\n",
      "Completed 11\n",
      "Completed 12\n",
      "Completed 13\n",
      "Completed 14\n",
      "Completed 15\n",
      "Completed 16\n",
      "Completed 17\n",
      "Completed 18\n",
      "Completed 19\n",
      "Completed 20\n",
      "Completed 21\n",
      "Completed 22\n",
      "Completed 23\n",
      "Completed 24\n",
      "Completed 25\n",
      "Completed 26\n",
      "Completed 27\n",
      "Completed 28\n",
      "Completed 29\n",
      "Completed 30\n",
      "Completed 31\n",
      "Completed 32\n",
      "Completed 33\n",
      "Completed 34\n",
      "Completed 35\n",
      "Completed 36\n",
      "Completed 37\n",
      "Completed 38\n",
      "Completed 39\n",
      "Completed 40\n",
      "Completed 41\n",
      "Completed 42\n",
      "Completed 43\n",
      "Completed 44\n",
      "Completed 45\n",
      "Completed 46\n",
      "Completed 47\n",
      "Completed 48\n",
      "Completed 49\n",
      "Completed 50\n",
      "Completed 51\n",
      "Completed 52\n",
      "Completed 53\n",
      "Completed 54\n",
      "Completed 55\n",
      "Completed 56\n",
      "Completed 57\n",
      "Completed 58\n",
      "Completed 59\n",
      "Completed 60\n",
      "Completed 61\n",
      "Completed 62\n",
      "Completed 63\n",
      "Completed 64\n",
      "Completed 65\n",
      "Completed 66\n",
      "Completed 67\n",
      "Completed 68\n",
      "Completed 69\n",
      "Completed 70\n",
      "Completed 71\n",
      "Completed 72\n",
      "Completed 73\n",
      "Completed 74\n",
      "Completed 75\n",
      "Completed 76\n",
      "Completed 77\n",
      "Completed 78\n",
      "Completed 79\n",
      "Completed 80\n",
      "Completed 81\n",
      "Completed 82\n",
      "Completed 83\n",
      "Completed 84\n",
      "Completed 85\n",
      "Completed 86\n",
      "Completed 87\n",
      "Completed 88\n",
      "Completed 89\n",
      "Completed 90\n",
      "Completed 91\n",
      "Completed 92\n",
      "Completed 93\n",
      "Completed 94\n",
      "Completed 95\n",
      "Completed 96\n",
      "Completed 97\n",
      "Completed 98\n",
      "Completed 99\n"
     ]
    }
   ],
   "source": [
    "train_dps=[]\n",
    "for i in range(100): \n",
    "    entry = ds[\"train\"][i]\n",
    "    train_dps.append(convert_input(entry['title'] + \" \" + entry['content'], \"gpt2\"))\n",
    "    print(f\"Completed {i}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb7ae9b9-e50f-4fa6-bf4a-a35e0d63d45d",
   "metadata": {},
   "outputs": [],
   "source": [
    "mp = \"/net/scratch/weak_to_strong/weak-to-strong/results/default/bs=32-dn=amaz_pola-e=2-ee=1000000-lp=0-l=xent-l=5e-05-ls=cosi_anne-mc=1024-ms=gpt2-nd=20000-ntd=10000-o=adam-s=0-twd=0\"\n",
    "#fine-tuned model path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb35fb76",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pre_ft_activations, post_ft_activations = extract_act_pipeline(\"gpt2\", train_dps, mp) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "640b2e34",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pre_ft_activations' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mpre_ft_activations\u001b[49m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'pre_ft_activations' is not defined"
     ]
    }
   ],
   "source": [
    "pre_ft_activations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fd17619d",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pre_ft_activations' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m final_preact \u001b[38;5;241m=\u001b[39m avg_samples(\u001b[43mpre_ft_activations\u001b[49m)\n\u001b[1;32m      2\u001b[0m final_postact \u001b[38;5;241m=\u001b[39m avg_samples(post_ft_activations)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'pre_ft_activations' is not defined"
     ]
    }
   ],
   "source": [
    "final_preact = avg_samples(pre_ft_activations)\n",
    "final_postact = avg_samples(post_ft_activations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77232bed",
   "metadata": {},
   "outputs": [],
   "source": [
    "A_optimized, delta_optimized = optimize_Adelta(pre_ft_activations, post_ft_activations, 32)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c008b59",
   "metadata": {},
   "source": [
    "### Usage Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "836ed35b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'gpt2-medium'\n",
    "\n",
    "strong_model_fintuned_path = \"/net/scratch/weak_to_strong/weak-to-strong/results/default/bs=32-dn=sciq-e=2-ee=1000000-lp=0-l=xent-l=5e-05-ls=cosi_anne-mc=1024-ms=gpt2-medium-nd=20000-ntd=10000-o=adam-s=0-twd=0-wms=gpt2/model.safetensors\"\n",
    "\n",
    "# activations1, activations2 = compare_models(model_name, strong_model_fintuned_path, test_datapoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cbae44a",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_datapoint = convert_input(\"Summary Changes of state are examples of phase changes, or phase transitions. All phase changes are accompanied by changes in the energy of a system. Changes from a more-ordered state to a less-ordered state (such as a liquid to a gas) areendothermic. Changes from a less-ordered state to a more-ordered state (such as a liquid to a solid) are always exothermic. The conversion of a solid to a liquid is called fusion (or melting). The energy required to melt 1 mol of a substance is its enthalpy of fusion (ΔHfus). The energy change required to vaporize 1 mol of a substance is the enthalpy of vaporization (ΔHvap). The direct conversion of a solid to a gas is sublimation. The amount of energy needed to sublime 1 mol of a substance is its enthalpy of sublimation (ΔHsub) and is the sum of the enthalpies of fusion and vaporization. Plots of the temperature of a substance versus heat added or versus heating time at a constant rate of heating are calledheating curves. Heating curves relate temperature changes to phase transitions. A superheated liquid, a liquid at a temperature and pressure at which it should be a gas, is not stable. A cooling curve is not exactly the reverse of the heating curve because many liquids do not freeze at the expected temperature. Instead, they form a supercooled liquid, a metastable liquid phase that exists below the normal melting point. Supercooled liquids usually crystallize on standing, or adding a seed crystal of the same or another substance can induce crystallization.\", model_name)\n",
    "\n",
    "\n",
    "activations1, activations2 = compare_models(model_name, finetuned_model_path, test_datapoint)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa7fe1ea",
   "metadata": {},
   "source": [
    "# Testing with GPT2 finetuned on Polarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb4ff4d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'gpt2'\n",
    "tokenizer = GPT2Tokenizer.from_pretrained(model_name)\n",
    "\n",
    "finetuned_model_path = \"/home/slhleosun/weak-to-strong-main/results/default/bs=32-dn=amaz_pola-e=2-ee=1000000-lp=0-l=xent-l=5e-05-ls=cosi_anne-mc=1024-ms=gpt2-nd=20000-ntd=10000-o=adam-s=0-twd=0/model.safetensors\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28e48c1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# datapoint = torch.randint(50257, (1, 10))  # Sample input ids, assuming GPT-2's vocabulary size\n",
    "\n",
    "test_datapoint = convert_input(\"This sound track was beautiful! It paints the senery in your mind so well I would recomend it even to people who hate vid. game music! I have played the game Chrono Cross but out of all of the games I have ever played it has the best music! It backs away from crude keyboarding and takes a fresher step with grate guitars and soulful orchestras. It would impress anyone who cares to listen! ^_^\", model_name)\n",
    "\n",
    "\n",
    "activations1, activations2 = compare_models(model_name, finetuned_model_path, test_datapoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "750ef39c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "activations1, activations2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e279993",
   "metadata": {},
   "source": [
    "# Linear Probe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bb28f5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "polarity_ds = load_dataset(\"amazon_polarity\")\n",
    "data_len = polarity_ds[\"train\"].num_rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72f5eb2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac5d0097",
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "\n",
    "activations_pre = []\n",
    "activations_post = []\n",
    "labels = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "385d1e87",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "while i < 300: \n",
    "    print(\"Working on \" + str(i))\n",
    "    datapoint = convert_input(polarity_ds['train'][i][\"title\"] + \" \" + polarity_ds['train'][i][\"content\"], model_name)\n",
    "    label = polarity_ds['train'][i][\"label\"]\n",
    "    act1, act2 = compare_models(model_name, finetuned_model_path, datapoint) \n",
    "    act1 = act1[\"h.11\"]\n",
    "    act2 = act2[\"h.11\"]\n",
    "    if act1.ndim == 3:\n",
    "        act1 = act1.mean(axis=1)\n",
    "    if act2.ndim == 3:\n",
    "        act2 = act2.mean(axis=1)\n",
    "    activations_pre.append(act1)\n",
    "    activations_post.append(act2)\n",
    "    labels.append(label)\n",
    "    \n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a80c597b",
   "metadata": {},
   "outputs": [],
   "source": [
    "i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59f71a51",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eea341a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "def linear_probe(activations, labels):\n",
    "\n",
    "    X = np.array([(np.array([1]) + act.detach().cpu().numpy()).mean(axis=0) for act in activations])\n",
    "    y = np.array(labels)\n",
    "\n",
    "    print(X.shape)\n",
    "    # Split into train and test sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "    # Initialize and train the linear classifier\n",
    "    clf = LogisticRegression(max_iter=1000)\n",
    "    clf.fit(X_train, y_train)\n",
    "\n",
    "    # Predict on the test set\n",
    "    y_pred = clf.predict(X_test)\n",
    "\n",
    "    # Calculate the accuracy\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    print(f'Accuracy: {accuracy:.2f}')\n",
    "    return clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "201c40ac",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "clf = linear_probe(activations_post, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79ae4975",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "plt.bar(range(len(clf.coef_[0])), clf.coef_[0])\n",
    "plt.xlabel('Features')\n",
    "plt.ylabel('Coefficient Value')\n",
    "plt.title('Feature Importance')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fddbbbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "X = np.array([(np.array([1]) + act.detach().cpu().numpy()).mean(axis=0) for act in activations_post])\n",
    "y = np.array(labels)\n",
    "\n",
    "# Project data to 2D using PCA\n",
    "pca = PCA(n_components=2)\n",
    "X_r = pca.fit_transform(X)\n",
    "\n",
    "# Fit logistic regression on the 2D projected data\n",
    "clf_2d = LogisticRegression()\n",
    "clf_2d.fit(X_r, y)\n",
    "\n",
    "# Create a mesh to plot the decision boundary\n",
    "x_min, x_max = X_r[:, 0].min() - .5, X_r[:, 0].max() + .5\n",
    "y_min, y_max = X_r[:, 1].min() - .5, X_r[:, 1].max() + .5\n",
    "h = .02  # step size in the mesh\n",
    "xx, yy = np.meshgrid(np.arange(x_min, x_max, h), np.arange(y_min, y_max, h))\n",
    "Z = clf_2d.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "\n",
    "# Plot decision boundary and data points\n",
    "Z = Z.reshape(xx.shape)\n",
    "plt.contourf(xx, yy, Z, alpha=0.8)\n",
    "plt.scatter(X_r[:, 0], X_r[:, 1], c=y, edgecolors='k', cmap=plt.cm.Paired)\n",
    "plt.xlabel('PCA Component 1')\n",
    "plt.ylabel('PCA Component 2')\n",
    "plt.title('2D PCA Projection and Decision Boundary')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c71abd4a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print_layer_names(activations1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b5f675d",
   "metadata": {},
   "source": [
    "    wte: Word Token Embeddings - The embedding matrix for input tokens.\n",
    "    wpe: Word Position Embeddings - The embedding matrix for the position of tokens in the sequence.\n",
    "    drop: Dropout - A regularization layer that randomly sets input units to 0 at each update during training time to prevent overfitting.\n",
    "    h: Indicates a layer of the transformer. The number following h denotes the index of the layer within the model (e.g., h.0 is the first layer, h.1 is the second layer, and so on).\n",
    "    ln_1, ln_2: Layer Normalization - Normalizes the input layer by re-centering and re-scaling, often used before or after the self-attention and feed-forward components in transformer blocks.\n",
    "    attn: Attention - The self-attention mechanism of the transformer. This component helps the model to focus on different parts of the input sequence when making predictions.\n",
    "        c_attn: Creates the query, key, and value projections for the attention mechanism.\n",
    "        attn_dropout: Dropout applied to the attention scores.\n",
    "        c_proj: Projects the output of the attention mechanism back to the hidden size dimensions.\n",
    "        resid_dropout: Dropout applied to the residual connection (often added after the attention output and before layer normalization).\n",
    "    mlp: Multi-Layer Perceptron - A small feed-forward neural network that follows the attention mechanism in each transformer block. It usually consists of two linear layers with an activation in between.\n",
    "        c_fc: The first linear layer (fully connected) of the MLP.\n",
    "        act: The activation function of the MLP (e.g., GELU or ReLU).\n",
    "        c_proj: The second linear layer of the MLP.\n",
    "        dropout: Dropout applied within the MLP to prevent overfitting.\n",
    "    ln_f: Final Layer Normalization - The layer normalization applied after the last transformer block, before the final output layer."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a1b6ebb",
   "metadata": {},
   "source": [
    "### Guide for Interpreting the Graphs \n",
    "- The relative position of blue and red dots indicates how similar or different the activations are before and after finetuning. If they overlap significantly, the representations are relatively stable through finetuning. If they are separate, it suggests that finetuning has significantly shifted the activations.\n",
    "- The shift from blue to red dots indicates the direction of change in the hidden states due to finetuning. For instance, if the red dots are predominantly to the right of the blue dots, this indicates that the activations have shifted along the direction represented by PCA Component 1.\n",
    "- Any consistent pattern of shift (e.g., most red dots are in a specific quadrant relative to the blue dots) may suggest how finetuning has affected the internal representations of the neural network. Perhaps the finetuning has made the network more sensitive to certain features, or has made it focus on different aspects of the input data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b0ab356",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_activation_changes(activations1, activations2, 'h.11', method='PCA')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0b9309d",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_activation_changes(activations1, activations2, 'h.11.mlp', method='PCA')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba5909a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_activation_changes(activations1, activations2, 'h.10', method='PCA')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8898bce1",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_activation_changes(activations1, activations2, 'h.10.mlp', method='PCA')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b795ad1",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_activation_changes(activations1, activations2, 'h.9', method='PCA')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45914935",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_activation_changes(activations1, activations2, 'h.8', method='PCA')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "838d318b",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_activation_changes(activations1, activations2, 'h.7', method='PCA')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68d957ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_activation_changes(activations1, activations2, 'h.6.mlp', method='PCA')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5195354b",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_activation_changes(activations1, activations2, 'h.6', method='PCA')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0ac0ce0",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_activation_changes(activations1, activations2, 'h.5.mlp', method='PCA')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27d1d7ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_activation_changes(activations1, activations2, 'h.4.mlp', method='PCA')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e58b218",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_activation_changes(activations1, activations2, 'h.3.mlp', method='PCA')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e7540f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_activation_changes(activations1, activations2, 'h.2.mlp', method='PCA')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f18d97e",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_activation_changes(activations1, activations2, 'h.1.mlp', method='PCA')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10412fb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_activation_changes(activations1, activations2, 'h.0.mlp', method='PCA')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f06456dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_activation_changes(activations1, activations2, 'h.0.mlp', method='PCA')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15fd5128",
   "metadata": {},
   "source": [
    "# Legacy: Weight Changes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3493bdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_model_weights(model):\n",
    "    weights = []\n",
    "    # Iterate through each block in the GPT-2 transformer\n",
    "    for block in model.transformer.h:\n",
    "        # Each block has two main components: the attention mechanism and the MLP\n",
    "        # Extract weights from attention mechanism's query, key, value matrices\n",
    "        attn = block.attn\n",
    "        weights.append(attn.query.weight.data)\n",
    "        weights.append(attn.key.weight.data)\n",
    "        weights.append(attn.value.weight.data)\n",
    "        weights.append(attn.out.weight.data)\n",
    "        \n",
    "        # Extract weights from MLP\n",
    "        mlp = block.mlp\n",
    "        weights.append(mlp.c_fc.weight.data)\n",
    "        weights.append(mlp.c_proj.weight.data)\n",
    "    return weights\n",
    "\n",
    "weights_pre = pre_model.score.weight.detach().numpy()\n",
    "weights_post = post_model.score.weight.detach().numpy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14cfac96",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_weights(initial_weights, finetuned_weights):\n",
    "    fig, axs = plt.subplots(1, 2, figsize=(12, 12))\n",
    "    sns.heatmap(initial_weights, ax=axs[0], cmap='viridis')\n",
    "    axs[0].set_title('Initial Weights')\n",
    "    sns.heatmap(finetuned_weights, ax=axs[1], cmap='viridis')\n",
    "    axs[1].set_title('Fine-tuned Weights')\n",
    "    plt.show()\n",
    "    \n",
    "visualize_weights(weights_pre, weights_post)\n",
    "visualize_weight_changes(weights_pre, weights_post, \"linear head\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bfd9d7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "original_weights = pre_model.transformer.wte.weight.detach().numpy()  # Example: word embedding layer\n",
    "finetuned_weights = post_model.transformer.wte.weight.detach().numpy()\n",
    "\n",
    "visualize_weights(original_weights, finetuned_weights)\n",
    "visualize_weight_changes(original_weights, finetuned_weights, \"word embedding\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4b927dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "original_weights = pre_model.transformer.wte.weight.detach().numpy()  # Example: word embedding layer\n",
    "finetuned_weights = post_model.transformer.wte.weight.detach().numpy()\n",
    "\n",
    "visualize_weights(original_weights, finetuned_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec21b8ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "original_query_weights = original_model.transformer.h[0].attn.c_attn.weight.detach().numpy()\n",
    "original_key_weightsb = original_model.transformer.h[0].attn.c_attn.weight.detach().numpy()\n",
    "original_value_weights = original_model.transformer.h[0].attn.c_attn.weight.detach().numpy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fed1584d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "def visualize_weight_changes(initial_weights, finetuned_weights, layer_name):\n",
    "    # Calculate the absolute differences between the weights\n",
    "    weight_differences = finetuned_weights - initial_weights\n",
    "    \n",
    "    # Normalize the differences to have a better visual comparison\n",
    "    # This is optional and can be commented out if raw differences are preferred\n",
    "    weight_differences = weight_differences / np.std(weight_differences)\n",
    "    \n",
    "    # Visualize the differences using a heatmap\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    sns.heatmap(weight_differences, cmap='coolwarm', center=0)\n",
    "    plt.title(f'Weight Changes in {layer_name}')\n",
    "    plt.xlabel('Neurons in Previous Layer')\n",
    "    plt.ylabel('Neurons in Current Layer')\n",
    "    plt.colorbar(label='Magnitude of Weight Change')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7faa01e",
   "metadata": {},
   "outputs": [],
   "source": [
    "original_ffn_weights = pre_model.transformer.h[0].mlp.c_fc.weight.detach().numpy()\n",
    "finetuned_ffn_weights = post_model.transformer.h[0].mlp.c_fc.weight.detach().numpy()\n",
    "\n",
    "visualize_weights(original_ffn_weights, finetuned_ffn_weights)\n",
    "visualize_weight_changes(original_ffn_weights, finetuned_ffn_weights, \"ffn\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97c2f074",
   "metadata": {},
   "outputs": [],
   "source": [
    "original_weights = pre_model.transformer.h[0].attn.c_proj.weight.detach().numpy()\n",
    "finetuned_weights = post_model.transformer.h[0].attn.c_proj.weight.detach().numpy()\n",
    "\n",
    "visualize_weights(original_weights, finetuned_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1c37b22",
   "metadata": {},
   "outputs": [],
   "source": [
    "tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ad386b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "post_model = TransformerWithHead.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9daaa639",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
